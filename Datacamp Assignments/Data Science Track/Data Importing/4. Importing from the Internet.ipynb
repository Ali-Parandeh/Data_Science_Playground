{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing from the Internet\n",
    "\n",
    "## 1. Importing Flat files\n",
    "\n",
    "### 1.1 Importing flat files from the web\n",
    "\n",
    "The flat file to import will be `'winequality-red.csv'` from the University of California, Irvine's [Machine Learning repository](http://archive.ics.uci.edu/ml/index.html). The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = \"https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv\"\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, \"datasets/winequality-red.csv\")\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('datasets/winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Opening and reading flat files from the web\n",
    "You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using pandas. In particular, you can use the function `pd.read_csv()` with the `URL` as the first argument and the separator `sep` as the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = \"https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv\"\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep = \";\")\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot first column of df\n",
    "pd.DataFrame.hist(df.iloc[:, 0:1])\n",
    "plt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Importing non-flat files from the web\n",
    "Use `pd.read_excel()` to import an Excel spreadsheet.\n",
    "\n",
    "Use `pd.read_excel()` to read in all of its sheets, print the sheet names and then print the head of the first sheet using its name, not its index.\n",
    "\n",
    "Note that the output of `pd.read_excel()` is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['1700', '1900'])\n"
     ]
    }
   ],
   "source": [
    "# Assign url of file: url\n",
    "url = 'http://s3.amazonaws.com/assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url, sheet_name = None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xl.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 country       1700\n",
      "0            Afghanistan  34.565000\n",
      "1  Akrotiri and Dhekelia  34.616667\n",
      "2                Albania  41.312000\n",
      "3                Algeria  36.720000\n",
      "4         American Samoa -14.307000\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xl[\"1700\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performing HTTP requests in Python using urllib\n",
    "\n",
    "Perform a GET request to extract information from Google.\n",
    "\n",
    "Extract HTML itself. Right now, however, you are going to package and send the request and then catch the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.request.Request'>\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"http://www.google.com/\"\n",
    "\n",
    "# This packages the request: request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(request))\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Printing HTTP request results in Python using urllib\n",
    "You packaged and sent a GET request to \"http://www.google.com/\" and then caught the response. Such a response is a http.client.HTTPResponse object. The question remains: what can you do with this response?\n",
    "\n",
    "Well, as it came from an HTML page, you could read it to extract the HTML and, in fact, such a http.client.HTTPResponse object has an associated read() method. Here, extract the response and print the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<HTML>\\n\\n<HEAD>\\n<TITLE>Guido\\'s Personal Home Page</TITLE>\\n</HEAD>\\n\\n<BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\">\\n\\n<H1>\\n<a href=\"pics.html\"><img border=\"0\" src=\"images/IMG_2192.jpg\"></a>\\nGuido van Rossum - Personal Home Page\\n<a href=\"pics.html\"><img border=0 width=270 height=216 src=\"images/guido-headshot-2019.jpg\"></a>\\n</H1>\\n\\n<P><A\\nHREF=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\" \\n><i>\"Gawky and proud of it.\"</i></A>\\n\\n\\n<H3><a\\nhref=\"http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\" >Who\\nI Am</a></H3>\\n\\n<p>Read\\nmy <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\"King\\'s\\nDay Speech\"</a> for some inspiration.\\n\\n<P>I am the author of the <A HREF=\"http://www.python.org\" >Python</A>\\nprogramming language.  See also my <A HREF=\"Resume.html\">resume</A>\\nand my <A HREF=\"Publications.html\">publications list</A>, a <A\\nHREF=\"bio.html\" >brief bio</A>, assorted <a\\nhref=\"http://legacy.python.org/doc/essays/\">writings</a>, <a\\nhref=\"http://legacy.python.org/doc/essays/ppt/\">presentations</a> and <a\\nhref=\"interviews.html\">interviews</a> (all about Python), some\\n<a href=\"pics.html\">pictures of me</a>,\\n<a href=\"http://neopythonic.blogspot.com\">my new blog</a>, and\\nmy <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">old\\nblog</a> on Artima.com.  I am\\n<a href=https://twitter.com/gvanrossum>@gvanrossum</a> on Twitter.\\n\\n<p>In January 2013 I joined\\n<a href=http://www.dropbox.com>Dropbox</a>.  I work on various Dropbox\\nproducts and have 50% for my Python work, no strings attached.\\nPreviously, I have worked for Google, Elemental Security, Zope\\nCorporation, BeOpen.com, CNRI, CWI, and SARA.  (See\\nmy <a href=Resume.html>resume</a>.)  I created Python while at CWI.\\n\\n<H3>How to Reach Me</H3>\\n\\n<P>You can send email for me to guido (at) python.org.\\nI read everything sent there, but if you ask\\nme a question about using Python, it\\'s likely that I won\\'t have time\\nto answer it, and will instead refer you to\\nhelp (at) python.org,\\n<a href=\"http://groups.google.com/groups?q=comp.lang.python\"\\n>comp.lang.python</a> or\\n<a href=http://stackoverflow.com>StackOverflow</a>.  If you need to\\ntalk to me on the phone or send me something by snail mail, send me an\\nemail and I\\'ll gladly email you instructions on how to reach me.\\n\\n<H3>My Name</H3>\\n\\n<P>My name often poses difficulties for Americans.\\n\\n<P><b>Pronunciation:</b> in Dutch, the \"G\" in Guido is a hard G,\\npronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\\n<A HREF=\"guido.au\">sound clip</A>.)  However, if you\\'re\\nAmerican, you may also pronounce it as the Italian \"Guido\".  I\\'m not\\ntoo worried about the associations with mob assassins that some people\\nhave. :-)\\n\\n<P><b>Spelling:</b> my last name is two words, and I\\'d like to keep it\\nthat way, the spelling on some of my credit cards notwithstanding.\\nDutch spelling rules dictate that when used in combination with my\\nfirst name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\\nlast name is used alone to refer to me, it is capitalized, for\\nexample: \"As usual, Van Rossum was right.\"\\n\\n<P><b>Alphabetization:</b> in America, I show up in the alphabet under\\n\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\\nme under \"G\" in their address book...\\n\\n\\n<H3>More Hyperlinks</H3>\\n\\n<UL>\\n\\n<LI>Here\\'s a collection of <A HREF =\\n\"http://legacy.python.org/doc/essays/\" >essays</A> relating to Python\\nthat I\\'ve written, including the foreword I wrote for Mark Lutz\\' book\\n\"Programming Python\".<P>\\n\\n<li>I own the official <a href=\"images/license.jpg\"><img align=\"center\"\\nborder=\"0\" width=\"100\" height=\"75\" src=\"images/license_thumb.jpg\">\\nPython license.</a><p>\\n\\n</UL>\\n\\n<H3>The Audio File Formats FAQ</H3>\\n\\n<P>I was the original creator and maintainer of the Audio File Formats\\nFAQ.  It is now maintained by Chris Bagwell\\nat <A HREF=\"http://www.cnpbagwell.com/audio-faq\"\\n>http://www.cnpbagwell.com/audio-faq</A>.  And here is a link to\\n<a href=http://sox.sourceforge.net/>SOX</a>, to which I contributed\\nsome early code.\\n\\n</UL>\\n\\n<HR>\\n\\n<A HREF=\"images/internetdog.gif\">\"On the Internet, nobody knows you\\'re\\na dog.\"</A>\\n\\n<HR>\\n\\n</BODY>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Specify the url\n",
    "url = \"https://www.python.org/~guido/\"\n",
    "\n",
    "# This packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the response: html\n",
    "html = response.read()\n",
    "\n",
    "# Print the html\n",
    "print(html)\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Performing HTTP requests in Python using requests\n",
    "Using a higher-level requests library closing the connection is not required when using requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML>\n",
      "\n",
      "<HEAD>\n",
      "<TITLE>Guido's Personal Home Page</TITLE>\n",
      "</HEAD>\n",
      "\n",
      "<BODY BGCOLOR=\"#FFFFFF\" TEXT=\"#000000\">\n",
      "\n",
      "<H1>\n",
      "<a href=\"pics.html\"><img border=\"0\" src=\"images/IMG_2192.jpg\"></a>\n",
      "Guido van Rossum - Personal Home Page\n",
      "<a href=\"pics.html\"><img border=0 width=270 height=216 src=\"images/guido-headshot-2019.jpg\"></a>\n",
      "</H1>\n",
      "\n",
      "<P><A\n",
      "HREF=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\" \n",
      "><i>\"Gawky and proud of it.\"</i></A>\n",
      "\n",
      "\n",
      "<H3><a\n",
      "href=\"http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\" >Who\n",
      "I Am</a></H3>\n",
      "\n",
      "<p>Read\n",
      "my <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\"King's\n",
      "Day Speech\"</a> for some inspiration.\n",
      "\n",
      "<P>I am the author of the <A HREF=\"http://www.python.org\" >Python</A>\n",
      "programming language.  See also my <A HREF=\"Resume.html\">resume</A>\n",
      "and my <A HREF=\"Publications.html\">publications list</A>, a <A\n",
      "HREF=\"bio.html\" >brief bio</A>, assorted <a\n",
      "href=\"http://legacy.python.org/doc/essays/\">writings</a>, <a\n",
      "href=\"http://legacy.python.org/doc/essays/ppt/\">presentations</a> and <a\n",
      "href=\"interviews.html\">interviews</a> (all about Python), some\n",
      "<a href=\"pics.html\">pictures of me</a>,\n",
      "<a href=\"http://neopythonic.blogspot.com\">my new blog</a>, and\n",
      "my <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">old\n",
      "blog</a> on Artima.com.  I am\n",
      "<a href=https://twitter.com/gvanrossum>@gvanrossum</a> on Twitter.\n",
      "\n",
      "<p>In January 2013 I joined\n",
      "<a href=http://www.dropbox.com>Dropbox</a>.  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my <a href=Resume.html>resume</a>.)  I created Python while at CWI.\n",
      "\n",
      "<H3>How to Reach Me</H3>\n",
      "\n",
      "<P>You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "<a href=\"http://groups.google.com/groups?q=comp.lang.python\"\n",
      ">comp.lang.python</a> or\n",
      "<a href=http://stackoverflow.com>StackOverflow</a>.  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "\n",
      "<H3>My Name</H3>\n",
      "\n",
      "<P>My name often poses difficulties for Americans.\n",
      "\n",
      "<P><b>Pronunciation:</b> in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "<A HREF=\"guido.au\">sound clip</A>.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "<P><b>Spelling:</b> my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "<P><b>Alphabetization:</b> in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "<H3>More Hyperlinks</H3>\n",
      "\n",
      "<UL>\n",
      "\n",
      "<LI>Here's a collection of <A HREF =\n",
      "\"http://legacy.python.org/doc/essays/\" >essays</A> relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".<P>\n",
      "\n",
      "<li>I own the official <a href=\"images/license.jpg\"><img align=\"center\"\n",
      "border=\"0\" width=\"100\" height=\"75\" src=\"images/license_thumb.jpg\">\n",
      "Python license.</a><p>\n",
      "\n",
      "</UL>\n",
      "\n",
      "<H3>The Audio File Formats FAQ</H3>\n",
      "\n",
      "<P>I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at <A HREF=\"http://www.cnpbagwell.com/audio-faq\"\n",
      ">http://www.cnpbagwell.com/audio-faq</A>.  And here is a link to\n",
      "<a href=http://sox.sourceforge.net/>SOX</a>, to which I contributed\n",
      "some early code.\n",
      "\n",
      "</UL>\n",
      "\n",
      "<HR>\n",
      "\n",
      "<A HREF=\"images/internetdog.gif\">\"On the Internet, nobody knows you're\n",
      "a dog.\"</A>\n",
      "\n",
      "<HR>\n",
      "\n",
      "</BODY>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url: url\n",
    "url = \"https://www.python.org/~guido/\"\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Parsing HTML with BeautifulSoup\n",
    "Use the BeautifulSoup package to parse, prettify and extract information from HTML. Scrape the data from the webpage of Guido van Rossum, Python's very own Benevolent Dictator for Life. Prettify the HTML and then extract the text and the hyperlinks.\n",
    "\n",
    "The URL of interest is url = 'https://www.python.org/~guido/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Guido's Personal Home Page\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"#FFFFFF\" text=\"#000000\">\n",
      "  <h1>\n",
      "   <a href=\"pics.html\">\n",
      "    <img border=\"0\" src=\"images/IMG_2192.jpg\"/>\n",
      "   </a>\n",
      "   Guido van Rossum - Personal Home Page\n",
      "   <a href=\"pics.html\">\n",
      "    <img border=\"0\" height=\"216\" src=\"images/guido-headshot-2019.jpg\" width=\"270\"/>\n",
      "   </a>\n",
      "  </h1>\n",
      "  <p>\n",
      "   <a href=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\">\n",
      "    <i>\n",
      "     \"Gawky and proud of it.\"\n",
      "    </i>\n",
      "   </a>\n",
      "   <h3>\n",
      "    <a href=\"http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\">\n",
      "     Who\n",
      "I Am\n",
      "    </a>\n",
      "   </h3>\n",
      "   <p>\n",
      "    Read\n",
      "my\n",
      "    <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\n",
      "     \"King's\n",
      "Day Speech\"\n",
      "    </a>\n",
      "    for some inspiration.\n",
      "    <p>\n",
      "     I am the author of the\n",
      "     <a href=\"http://www.python.org\">\n",
      "      Python\n",
      "     </a>\n",
      "     programming language.  See also my\n",
      "     <a href=\"Resume.html\">\n",
      "      resume\n",
      "     </a>\n",
      "     and my\n",
      "     <a href=\"Publications.html\">\n",
      "      publications list\n",
      "     </a>\n",
      "     , a\n",
      "     <a href=\"bio.html\">\n",
      "      brief bio\n",
      "     </a>\n",
      "     , assorted\n",
      "     <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "      writings\n",
      "     </a>\n",
      "     ,\n",
      "     <a href=\"http://legacy.python.org/doc/essays/ppt/\">\n",
      "      presentations\n",
      "     </a>\n",
      "     and\n",
      "     <a href=\"interviews.html\">\n",
      "      interviews\n",
      "     </a>\n",
      "     (all about Python), some\n",
      "     <a href=\"pics.html\">\n",
      "      pictures of me\n",
      "     </a>\n",
      "     ,\n",
      "     <a href=\"http://neopythonic.blogspot.com\">\n",
      "      my new blog\n",
      "     </a>\n",
      "     , and\n",
      "my\n",
      "     <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">\n",
      "      old\n",
      "blog\n",
      "     </a>\n",
      "     on Artima.com.  I am\n",
      "     <a href=\"https://twitter.com/gvanrossum\">\n",
      "      @gvanrossum\n",
      "     </a>\n",
      "     on Twitter.\n",
      "     <p>\n",
      "      In January 2013 I joined\n",
      "      <a href=\"http://www.dropbox.com\">\n",
      "       Dropbox\n",
      "      </a>\n",
      "      .  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my\n",
      "      <a href=\"Resume.html\">\n",
      "       resume\n",
      "      </a>\n",
      "      .)  I created Python while at CWI.\n",
      "      <h3>\n",
      "       How to Reach Me\n",
      "      </h3>\n",
      "      <p>\n",
      "       You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "       <a href=\"http://groups.google.com/groups?q=comp.lang.python\">\n",
      "        comp.lang.python\n",
      "       </a>\n",
      "       or\n",
      "       <a href=\"http://stackoverflow.com\">\n",
      "        StackOverflow\n",
      "       </a>\n",
      "       .  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "       <h3>\n",
      "        My Name\n",
      "       </h3>\n",
      "       <p>\n",
      "        My name often poses difficulties for Americans.\n",
      "        <p>\n",
      "         <b>\n",
      "          Pronunciation:\n",
      "         </b>\n",
      "         in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "         <a href=\"guido.au\">\n",
      "          sound clip\n",
      "         </a>\n",
      "         .)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "         <p>\n",
      "          <b>\n",
      "           Spelling:\n",
      "          </b>\n",
      "          my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "          <p>\n",
      "           <b>\n",
      "            Alphabetization:\n",
      "           </b>\n",
      "           in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "           <h3>\n",
      "            More Hyperlinks\n",
      "           </h3>\n",
      "           <ul>\n",
      "            <li>\n",
      "             Here's a collection of\n",
      "             <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "              essays\n",
      "             </a>\n",
      "             relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "             <p>\n",
      "              <li>\n",
      "               I own the official\n",
      "               <a href=\"images/license.jpg\">\n",
      "                <img align=\"center\" border=\"0\" height=\"75\" src=\"images/license_thumb.jpg\" width=\"100\"/>\n",
      "                Python license.\n",
      "               </a>\n",
      "               <p>\n",
      "               </p>\n",
      "              </li>\n",
      "             </p>\n",
      "            </li>\n",
      "           </ul>\n",
      "           <h3>\n",
      "            The Audio File Formats FAQ\n",
      "           </h3>\n",
      "           <p>\n",
      "            I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at\n",
      "            <a href=\"http://www.cnpbagwell.com/audio-faq\">\n",
      "             http://www.cnpbagwell.com/audio-faq\n",
      "            </a>\n",
      "            .  And here is a link to\n",
      "            <a href=\"http://sox.sourceforge.net/\">\n",
      "             SOX\n",
      "            </a>\n",
      "            , to which I contributed\n",
      "some early code.\n",
      "           </p>\n",
      "          </p>\n",
      "         </p>\n",
      "        </p>\n",
      "       </p>\n",
      "      </p>\n",
      "     </p>\n",
      "    </p>\n",
      "   </p>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "<hr/>\n",
      "<a href=\"images/internetdog.gif\">\n",
      " \"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "</a>\n",
      "<hr/>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r= requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Turning a webpage into data using BeautifulSoup: getting the text\n",
    "\n",
    "Extract information from HTML soup. Extract text from the BDFL's webpage, along with printing the webpage's title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "\n",
      "\n",
      "Guido's Personal Home Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guido van Rossum - Personal Home Page\n",
      "\n",
      "\n",
      "\"Gawky and proud of it.\"\n",
      "Who\n",
      "I Am\n",
      "Read\n",
      "my \"King's\n",
      "Day Speech\" for some inspiration.\n",
      "\n",
      "I am the author of the Python\n",
      "programming language.  See also my resume\n",
      "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
      "pictures of me,\n",
      "my new blog, and\n",
      "my old\n",
      "blog on Artima.com.  I am\n",
      "@gvanrossum on Twitter.\n",
      "\n",
      "In January 2013 I joined\n",
      "Dropbox.  I work on various Dropbox\n",
      "products and have 50% for my Python work, no strings attached.\n",
      "Previously, I have worked for Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my resume.)  I created Python while at CWI.\n",
      "\n",
      "How to Reach Me\n",
      "You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but if you ask\n",
      "me a question about using Python, it's likely that I won't have time\n",
      "to answer it, and will instead refer you to\n",
      "help (at) python.org,\n",
      "comp.lang.python or\n",
      "StackOverflow.  If you need to\n",
      "talk to me on the phone or send me something by snail mail, send me an\n",
      "email and I'll gladly email you instructions on how to reach me.\n",
      "\n",
      "My Name\n",
      "My name often poses difficulties for Americans.\n",
      "\n",
      "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "sound clip.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "Spelling: my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "Alphabetization: in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "More Hyperlinks\n",
      "\n",
      "Here's a collection of essays relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "I own the official \n",
      "Python license.\n",
      "\n",
      "The Audio File Formats FAQ\n",
      "I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
      "SOX, to which I contributed\n",
      "some early code.\n",
      "\n",
      "\n",
      "\n",
      "\"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text= soup.get_text()\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Turning a webpage into data using BeautifulSoup: getting the hyperlinks\n",
    "Extract the URLs of the hyperlinks from the BDFL's webpage. Use the soup method `find_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "pics.html\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "http://metalab.unc.edu/Dave/Dr-Fun/df200004/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "http://www.dropbox.com\n",
      "Resume.html\n",
      "http://groups.google.com/groups?q=comp.lang.python\n",
      "http://stackoverflow.com\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using APIs\n",
    "### 3.1 API requests\n",
    "Pull some movie data down from the Open Movie Database (OMDB) using their API. The movie you'll query the API about is The Social Network. Recall that, in the video, to query the API about the movie `The Social Network`.\n",
    "\n",
    "Note: recently, OMDB has changed their API and an API key also needs to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Title\":\"The Social Network\",\"Year\":\"2010\",\"Rated\":\"PG-13\",\"Released\":\"01 Oct 2010\",\"Runtime\":\"120 min\",\"Genre\":\"Biography, Drama\",\"Director\":\"David Fincher\",\"Writer\":\"Aaron Sorkin (screenplay), Ben Mezrich (book)\",\"Actors\":\"Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\",\"Plot\":\"Harvard student Mark Zuckerberg creates the social networking site. That would become known as Facebook but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\",\"Language\":\"English, French\",\"Country\":\"USA\",\"Awards\":\"Won 3 Oscars. Another 165 wins & 168 nominations.\",\"Poster\":\"https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\",\"Ratings\":[{\"Source\":\"Internet Movie Database\",\"Value\":\"7.7/10\"},{\"Source\":\"Rotten Tomatoes\",\"Value\":\"95%\"},{\"Source\":\"Metacritic\",\"Value\":\"95/100\"}],\"Metascore\":\"95\",\"imdbRating\":\"7.7\",\"imdbVotes\":\"571,335\",\"imdbID\":\"tt1285016\",\"Type\":\"movie\",\"DVD\":\"11 Jan 2011\",\"BoxOffice\":\"$96,400,000\",\"Production\":\"Columbia Pictures\",\"Website\":\"http://www.thesocialnetwork-movie.com/\",\"Response\":\"True\"}\n"
     ]
    }
   ],
   "source": [
    "# Import requests package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = \"http://www.omdbapi.com/?t=the+social+network\"\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Print the text of the response\n",
    "print (r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 JSON–from the web to Python\n",
    "Decode the JSON and print the key-value pairs of the resulting dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  The Social Network\n",
      "Year:  2010\n",
      "Rated:  PG-13\n",
      "Released:  01 Oct 2010\n",
      "Runtime:  120 min\n",
      "Genre:  Biography, Drama\n",
      "Director:  David Fincher\n",
      "Writer:  Aaron Sorkin (screenplay), Ben Mezrich (book)\n",
      "Actors:  Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\n",
      "Plot:  Harvard student Mark Zuckerberg creates the social networking site. That would become known as Facebook but is later sued by two brothers who claimed he stole their idea, and the co-founder who was later squeezed out of the business.\n",
      "Language:  English, French\n",
      "Country:  USA\n",
      "Awards:  Won 3 Oscars. Another 165 wins & 168 nominations.\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\n",
      "Ratings:  [{'Source': 'Internet Movie Database', 'Value': '7.7/10'}, {'Source': 'Rotten Tomatoes', 'Value': '95%'}, {'Source': 'Metacritic', 'Value': '95/100'}]\n",
      "Metascore:  95\n",
      "imdbRating:  7.7\n",
      "imdbVotes:  571,335\n",
      "imdbID:  tt1285016\n",
      "Type:  movie\n",
      "DVD:  11 Jan 2011\n",
      "BoxOffice:  $96,400,000\n",
      "Production:  Columbia Pictures\n",
      "Website:  http://www.thesocialnetwork-movie.com/\n",
      "Response:  True\n"
     ]
    }
   ],
   "source": [
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 The Wikipedia API\n",
    "One more API: the Wikipedia API (documented [here](https://www.mediawiki.org/wiki/API:Main_page)). Extract information from the Wikipedia page for Pizza.The query will return nested JSONs, that is, JSONs with JSONs, but Python can handle that because it will translate them into dictionaries within dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"mw-empty-elt\">\n",
      "</p>\n",
      "\n",
      "<p><b>Pizza</b> (<small>Italian: </small><span title=\"Representation in the International Phonetic Alphabet (IPA)\">[ˈpittsa]</span>, <small>Neapolitan: </small><span title=\"Representation in the International Phonetic Alphabet (IPA)\">[ˈpittsə]</span>) is a savory dish of Italian origin, consisting of a usually round, flattened base of leavened wheat-based dough topped with tomatoes, cheese, and various other ingredients (anchovies, olives, meat, etc.) baked at a high temperature, traditionally in a wood-fired oven. In formal settings, like a restaurant, pizza is eaten with knife and fork, but in casual settings it is cut into wedges to be eaten while held in the hand. Small pizzas are sometimes called pizzettas.\n",
      "</p><p>The term <i>pizza</i> was first recorded in the 10th century in a Latin manuscript from the Southern Italian town of Gaeta in Lazio, on the border with Campania. Modern pizza was invented in Naples, and the dish and its variants have since become popular in many countries. It has become one of the most popular foods in the world and a common fast food item in Europe and North America, available at pizzerias (restaurants specializing in pizza),  restaurants offering Mediterranean cuisine, and via pizza delivery. Many companies sell ready-baked frozen pizzas to be reheated in an ordinary home oven.\n",
      "</p><p>The <i>Associazione Verace Pizza Napoletana</i> (lit. True Neapolitan Pizza Association) is a non-profit organization founded in 1984 with headquarters in Naples that aims to promote traditional Neapolitan pizza. In 2009, upon Italy's request, Neapolitan pizza was registered with the European Union as a Traditional Speciality Guaranteed dish, and in 2017 the art of its making was included on UNESCO's list of intangible cultural heritage.</p>\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = \"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&exintro=&titles=pizza\"\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print the Wikipedia page extract\n",
    "pizza_extract = json_data['query']['pages']['24768']['extract']\n",
    "print(pizza_extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Twitter API\n",
    "### 4.1 Authentication\n",
    "The package tweepy is great at handling all the Twitter API OAuth Authentication details. Pass it your authentication credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import tweepy\n",
    "\n",
    "# Store OAuth authentication credentials in relevant variables\n",
    "at = \"z\"\n",
    "ats = \"s\"\n",
    "ck = \"y\"\n",
    "cs = \"x\"\n",
    "\n",
    "# Pass OAuth details to tweepy's OAuth handler\n",
    "auth = tweepy.OAuthHandler(ck, cs)\n",
    "auth.set_access_token(at, ats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Streaming tweets\n",
    "Now it is time to stream some tweets! A tweet stream listener class is defined as `MyStreamListener`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write( json.dumps(tweet) + '\\n' )\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Streamobject and to filter tweets according to particular keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Stream listener\n",
    "l = MyStreamListener()\n",
    "\n",
    "# Create your Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track=[\"clinton\", \"trump\", \"sanders\", \"cruz\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Load and explore your Twitter data\n",
    "Twitter data is now sitting locally in a text file, it's time to explore it! Read the Twitter data into a list: `tweets_data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import json\n",
    "\n",
    "# String of path to file: tweets_data_path\n",
    "tweets_data_path = \"tweets.txt\"\n",
    "\n",
    "# Initialize empty list to store tweets: tweets_data\n",
    "tweets_data = []\n",
    "\n",
    "# Open connection to file\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "\n",
    "# Read in tweets and store in list: tweets_data\n",
    "for line in tweets_file:\n",
    "    tweet = json.loads(line)\n",
    "    tweets_data.append(tweet)\n",
    "\n",
    "# Close connection to file\n",
    "tweets_file.close()\n",
    "\n",
    "# Print the keys of the first tweet dict\n",
    "print(tweets_data[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Twitter data to DataFrame\n",
    "Extract the text and language of each tweet. Build a DataFrame in which each row is a tweet and the columns are 'text' and 'lang'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame of tweet texts and languages\n",
    "df = pd.DataFrame(tweets_data, columns=[\"text\", \"lang\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 A little bit of Twitter text analysis\n",
    "Do a bit of text analysis to count how many tweets contain the words 'clinton', 'trump', 'sanders' and 'cruz'. Following function `word_in_text()` is defined, which will tell you whether the first argument (a word) occurs within the 2nd argument (a tweet).\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, text)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "Iterate over the rows of the DataFrame and calculate how many tweets contain each of our keywords! The list of objects for each candidate has been initialized to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store tweet counts\n",
    "[clinton, trump, sanders, cruz] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in df.iterrows():\n",
    "    clinton += word_in_text('clinton', row['text'])\n",
    "    trump += word_in_text(\"trump\", row[\"text\"])\n",
    "    sanders += word_in_text(\"sanders\", row[\"text\"])\n",
    "    cruz += word_in_text(\"cruz\", row[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Plotting your Twitter data\n",
    "Plot a bar chart of this data. You'll use the statistical data visualization library `seaborn`. First `import seaborn as sns`. Then construct a barplot of the data using `sns.barplot`, passing it two arguments:\n",
    "\n",
    "a list of labels and\n",
    "a list containing the variables you wish to plot (clinton, trump and so on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['clinton', 'trump', 'sanders', 'cruz']\n",
    "\n",
    "# Plot histogram\n",
    "ax = sns.barplot(cd, [clinton, trump, sanders, cruz])\n",
    "ax.set(ylabel=\"count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
